{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xy_all size: (145460, 24)\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read csv and delete RainTomorrow rows with empty\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "# train = train.dropna(subset=[\"RainTomorrow\"])\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# add missing value\n",
    "columns_miss_object = [\"RainToday\", \"RainTomorrow\"]\n",
    "\n",
    "for column in columns_miss_object:\n",
    "    train[column] = train[column].ffill().bfill()\n",
    "\n",
    "# union and cherk object and null data\n",
    "xy_all = pd.concat([train, test], axis=0)\n",
    "cat_features = [\n",
    "    \"Date\",\n",
    "    \"Location\",\n",
    "    \"WindGustDir\",\n",
    "    \"WindDir9am\",\n",
    "    \"WindDir3pm\",\n",
    "    \"RainToday\",\n",
    "    \"RainTomorrow\",\n",
    "    \"Evaporation\",\n",
    "    \"Sunshine\",\n",
    "    \"Cloud9am\",\n",
    "    \"Cloud3pm\",\n",
    "]\n",
    "\n",
    "# processing value\n",
    "# object(string) type to in32, NAN and missing value to -1\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(\n",
    "    dtype=np.int32,\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1,\n",
    "    encoded_missing_value=-1,\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "xy_all[cat_features] = ordinal_encoder.fit_transform(xy_all[cat_features])\n",
    "print(\"xy_all size:\", xy_all.shape)\n",
    "\n",
    "# Split\n",
    "# RainTomorrow with -1 is x_test\n",
    "# RainTomorrow without -1 is xy_train\n",
    "\n",
    "xy_train = xy_all[xy_all[\"RainTomorrow\"] != -1]\n",
    "x_train = xy_train.drop(columns=[\"RainTomorrow\"])\n",
    "y_train = xy_train[\"RainTomorrow\"]\n",
    "x_test = xy_all[xy_all[\"RainTomorrow\"] == -1].drop(columns=\"RainTomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3160\n",
      "[LightGBM] [Info] Number of data points in the train set: 101822, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 0.225973\n"
     ]
    }
   ],
   "source": [
    "# lightgbm model\n",
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    boosting_type=\"gbdt\",\n",
    "    num_leaves=165,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.04902036001758038,\n",
    "    n_estimators=380,\n",
    "    subsample_for_bin=200000,\n",
    "    objective=None,\n",
    "    class_weight=None,\n",
    "    min_split_gain=0.0,\n",
    "    min_child_weight=0.001,\n",
    "    min_child_samples=100,\n",
    "    subsample=0.8983143759937497,\n",
    "    colsample_bytree=0.8051100520465713,\n",
    "    reg_alpha=0.77069295356252,\n",
    "    reg_lambda= 0.17987509891243725,\n",
    "    random_state=42,\n",
    "    n_jobs=None,\n",
    "    importance_type=\"split\",\n",
    ")\n",
    "# train\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_lgbm_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost model\n",
    "param = {\n",
    "    \"subsample\": 0.6245374117658219,\n",
    "    \"reg_lambda\": 0.1556072714142416,\n",
    "    \"reg_alpha\": 0.993476368183754,\n",
    "    \"n_estimators\": 347,\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.051759029191354194,\n",
    "    \"colsample_bytree\": 0.9492330511297755,\n",
    "}\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(**param)\n",
    "# train\n",
    "model.fit(x_train, y_train, verbose=False)\n",
    "# pred\n",
    "y_xgb_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = 0.5 * y_lgbm_pred + 0.5 * y_xgb_pred\n",
    "y_pred_str = np.where(y_pred > 0.5, \"Yes\", \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save .csv\n",
    "pd.DataFrame({\"id\": x_test[\"id\"], \"RainTomorrow\": y_pred_str}).to_csv(\n",
    "    \"./output/LGBM+XGB.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
